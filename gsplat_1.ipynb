{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18bc3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install tqdm\n",
    "%pip install matplotlib\n",
    "%pip install piq\n",
    "%pip install imageio\n",
    "%pip install opencv-python\n",
    "%pip install tensorboard\n",
    "%pip install pycolmap\n",
    "%pip install pyquaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67807c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import json\n",
    "import pycolmap\n",
    "import os\n",
    "from pathlib import Path\n",
    "from piq import ssim\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ac416",
   "metadata": {},
   "source": [
    "# Build Gaussian Renderer CUDA Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setuptools import setup\n",
    "from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n",
    "\n",
    "setup(\n",
    "    name='gsplat',\n",
    "    ext_modules=[\n",
    "        CUDAExtension(\n",
    "            'gsplat',\n",
    "            sources=[\n",
    "                'gsplat.cpp',\n",
    "                'gsplat_sort.cu',\n",
    "                'gsplat_render.cu'\n",
    "            ],\n",
    "            extra_compile_args={'cxx': [], 'nvcc': ['-O3']}\n",
    "        )\n",
    "    ],\n",
    "    cmdclass={'build_ext': BuildExtension}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gsplat_render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5320f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "H, W = 512, 512\n",
    "tile_size = 16\n",
    "num_tiles_x = W // tile_size\n",
    "num_tiles_y = H // tile_size\n",
    "num_gaussians = 20000\n",
    "radius = 6.0  # pixels\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# --- 1. Generate Gaussians in 3D space ---\n",
    "torch.manual_seed(0)\n",
    "xyz = torch.randn(num_gaussians, 3, device=device) + torch.tensor([0.0, 0.0, 2.0], device=device)\n",
    "colors = torch.rand(num_gaussians, 3, device=device)\n",
    "alpha = torch.full((num_gaussians,), 0.6, device=device)\n",
    "\n",
    "# --- 2. Project to screen space ---\n",
    "fx = fy = 50\n",
    "cx, cy = W / 2, H / 2\n",
    "K = torch.tensor([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], device=device)\n",
    "xy = xyz[:, :2] / xyz[:, 2:3]\n",
    "uv = (K[:2, :2] @ xy.T).T + K[:2, 2]\n",
    "depth = xyz[:, 2]\n",
    "\n",
    "# --- 3. Duplicate Gaussians across overlapping tiles ---\n",
    "tile_ids, uv_list, depth_list, color_list, alpha_list = [], [], [], [], []\n",
    "\n",
    "for i in range(num_gaussians):\n",
    "    min_tx = max(0, int((uv[i, 0] - radius) // tile_size))\n",
    "    max_tx = min(num_tiles_x - 1, int((uv[i, 0] + radius) // tile_size))\n",
    "    min_ty = max(0, int((uv[i, 1] - radius) // tile_size))\n",
    "    max_ty = min(num_tiles_y - 1, int((uv[i, 1] + radius) // tile_size))\n",
    "    for tx in range(min_tx, max_tx + 1):\n",
    "        for ty in range(min_ty, max_ty + 1):\n",
    "            tile_id = ty * num_tiles_x + tx\n",
    "            tile_ids.append(tile_id)\n",
    "            uv_list.append(uv[i])\n",
    "            depth_list.append(depth[i])\n",
    "            color_list.append(colors[i])\n",
    "            alpha_list.append(alpha[i])\n",
    "\n",
    "tile_ids = torch.tensor(tile_ids, device=device)\n",
    "uv = torch.stack(uv_list)\n",
    "depth = torch.stack(depth_list)\n",
    "colors = torch.stack(color_list)\n",
    "alpha = torch.stack(alpha_list)\n",
    "\n",
    "# --- 4. Sort by tile + depth ---\n",
    "sort_key = tile_ids * 1e3 + depth\n",
    "idx = torch.argsort(sort_key)\n",
    "tile_ids, uv, depth, colors, alpha = tile_ids[idx], uv[idx], depth[idx], colors[idx], alpha[idx]\n",
    "\n",
    "# --- 5. Precompute pixel coords per tile ---\n",
    "tile_pixel_coords = []\n",
    "for ty in range(num_tiles_y):\n",
    "    for tx in range(num_tiles_x):\n",
    "        x = torch.arange(tx * tile_size, (tx + 1) * tile_size, device=device)\n",
    "        y = torch.arange(ty * tile_size, (ty + 1) * tile_size, device=device)\n",
    "        gx, gy = torch.meshgrid(x, y, indexing='xy')\n",
    "        coords = torch.stack([gx, gy], dim=-1).reshape(-1, 2)\n",
    "        tile_pixel_coords.append(coords)\n",
    "tile_pixel_coords = torch.stack(tile_pixel_coords)  # (num_tiles, tile_area, 2)\n",
    "\n",
    "# --- 6. Gaussian params ---\n",
    "cov = torch.eye(2, device=device) * 3.0\n",
    "inv_cov = torch.inverse(cov)\n",
    "\n",
    "# --- 7. Output buffers ---\n",
    "image = torch.zeros((H, W, 3), device=device)\n",
    "alpha_buf = torch.zeros((H, W), device=device)\n",
    "\n",
    "# --- 8. Rasterize per tile ---\n",
    "for tid in range(num_tiles_x * num_tiles_y):\n",
    "    in_tile = tile_ids == tid\n",
    "    if not in_tile.any():\n",
    "        continue\n",
    "\n",
    "    coords = tile_pixel_coords[tid]  # (tile_area, 2)\n",
    "    px, py = coords[:, 0].long(), coords[:, 1].long()\n",
    "    idx = (py, px)\n",
    "\n",
    "    guv = uv[in_tile]       # (M, 2)\n",
    "    gcol = colors[in_tile]  # (M, 3)\n",
    "    galpha = alpha[in_tile] # (M,)\n",
    "\n",
    "    diff = coords.unsqueeze(0) - guv.unsqueeze(1)  # (M, P, 2)\n",
    "    exp_term = -0.5 * torch.einsum(\"mpk,kl,mpk->mp\", diff, inv_cov, diff)\n",
    "    weights = torch.exp(exp_term).clamp(max=1.0)  # (M, P)\n",
    "\n",
    "    for m in range(guv.shape[0]):\n",
    "        a = galpha[m] * (1 - alpha_buf[idx]) * weights[m]\n",
    "        alpha_buf[idx] += a\n",
    "        image[idx] += a.unsqueeze(1) * gcol[m]\n",
    "\n",
    "# --- 9. Show result ---\n",
    "plt.imshow(image.clamp(0, 1).cpu().numpy())\n",
    "plt.title(\"GPU Vectorized Tiled Gaussian Splatting\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e6beb",
   "metadata": {},
   "source": [
    "# Structure From Motion Extraction to NERF Camera Poses/Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc18b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colmap_to_nerf_point(points):\n",
    "    # Same flip to move world into NeRF-style frame where Z-forward = negative\n",
    "    return points @ torch.diag(torch.tensor([1.0, -1.0, -1.0], dtype=points.dtype, device=points.device)).T\n",
    "\n",
    "def colmap_to_nerf_pose(pose):\n",
    "    flip = torch.diag(torch.tensor([1.0, -1.0, -1.0], dtype=pose.dtype, device=pose.device))\n",
    "    R = pose[:3, :3] @ flip\n",
    "    t = pose[:3, 3]\n",
    "    return torch.cat([\n",
    "        torch.cat([R, t.view(3, 1)], dim=1),\n",
    "        torch.tensor([[0.0, 0.0, 0.0, 1.0]], dtype=pose.dtype, device=pose.device)\n",
    "    ], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33def09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfm_extract(image_dir, device='cuda'):\n",
    "\n",
    "    image_dir = Path(image_dir)\n",
    "    database_path = Path(\"temp/database.db\")\n",
    "    sfm_path = Path(\"temp/sfm_output\")\n",
    "\n",
    "    if sfm_path.exists() and any(sfm_path.iterdir()):\n",
    "        print(f\"[INFO] Loading existing SfM reconstruction from {sfm_path}\")\n",
    "        reconstruction = pycolmap.Reconstruction(str(sfm_path / \"0\"))\n",
    "    else:\n",
    "        # Clean up previous runs\n",
    "        if database_path.exists():\n",
    "            database_path.unlink()\n",
    "        if sfm_path.exists():\n",
    "            shutil.rmtree(sfm_path)\n",
    "        sfm_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 1. Extract features\n",
    "        print(\"[INFO] Extracting features...\")\n",
    "\n",
    "        pycolmap.extract_features(\n",
    "            database_path=str(database_path),\n",
    "            image_path=str(image_dir),\n",
    "            camera_model='PINHOLE',\n",
    "            camera_mode='SINGLE'\n",
    "        )\n",
    "\n",
    "        # 2. Match features\n",
    "        print(\"[INFO] Matching features...\")\n",
    "        pycolmap.match_exhaustive(str(database_path))\n",
    "\n",
    "        # 3. Incremental mapping\n",
    "        print(\"[INFO] Performing incremental mapping...\")\n",
    "        reconstructions = pycolmap.incremental_mapping(\n",
    "            str(database_path),\n",
    "            str(image_dir),\n",
    "            str(sfm_path),\n",
    "            initial_image_pair_callback=lambda: print(\"[INFO] Initial image pair registered.\"),\n",
    "            next_image_callback=lambda: print(\"[INFO] Next image registered.\")\n",
    "        )\n",
    "\n",
    "        if not reconstructions:\n",
    "            raise RuntimeError(\"No reconstructions found\")\n",
    "        reconstruction = reconstructions[0]\n",
    "\n",
    "    print(f\"[INFO] Number of registered images: {len(reconstruction.images)}\")\n",
    "    print(f\"[INFO] Number of 3D points: {len(reconstruction.points3D)}\")\n",
    "\n",
    "    # Extract camera poses and intrinsics\n",
    "    pose_c2w_dict = {}\n",
    "    intrinsics_dict = {}\n",
    "    camera_models = set()\n",
    "\n",
    "    for img_id, img in reconstruction.images.items():\n",
    "        img_name = os.path.basename(img.name)\n",
    "        pose = torch.tensor(img.cam_from_world.matrix(), dtype=torch.float32, device=device)\n",
    "        intrinsics = torch.tensor(img.camera.params, dtype=torch.float32, device=device)\n",
    "\n",
    "        pose_c2w_dict[img_name] = colmap_to_nerf_pose(pose)\n",
    "        intrinsics_dict[img_name] = intrinsics\n",
    "\n",
    "        camera = img.camera\n",
    "        camera_models.add(camera.model)\n",
    "\n",
    "        print(f\"[CAMERA INFO] Image ID: {img_id}\")\n",
    "        print(f\" - Image name: {img.name}\")\n",
    "        print(f\" - Camera ID: {camera.camera_id}\")\n",
    "        print(f\" - Camera model: {camera.model}\")\n",
    "        print(f\" - Image size: {camera.width} x {camera.height}\")\n",
    "        print(f\" - Intrinsic parameters ({len(camera.params)}): {camera.params}\")\n",
    "        print(f\" - cam_from_world:\\n{img.cam_from_world.matrix()}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    if len(camera_models) == 1:\n",
    "        print(f\"[INFO] Single camera model detected: {list(camera_models)[0]}\")\n",
    "    else:\n",
    "        print(f\"[WARNING] Multiple camera models detected: {camera_models}\")\n",
    "\n",
    "    # Extract 3D points\n",
    "    points = (\n",
    "        torch.stack([\n",
    "            colmap_to_nerf_point(torch.tensor(p.xyz, dtype=torch.float32, device=device))\n",
    "            for p in reconstruction.points3D.values()\n",
    "        ])\n",
    "        if reconstruction.points3D else\n",
    "        torch.empty((0, 3), device=device)\n",
    "    )\n",
    "\n",
    "    return pose_c2w_dict, intrinsics_dict, points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4fa152",
   "metadata": {},
   "source": [
    "# Dataset with Optional Structure-From-Motion Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a410932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_homogeneous(pose_3x4):\n",
    "    bottom_row = torch.tensor([[0, 0, 0, 1]], dtype=pose_3x4.dtype, device=pose_3x4.device)\n",
    "    pose_4x4 = torch.cat([pose_3x4, bottom_row], dim=0)\n",
    "    return pose_4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeRFDataset(Dataset):\n",
    "    def __init__(self, json_path, image_size=(512, 512), device='cuda', sfm_poses=None, sfm_intrinsics=None):\n",
    "        with open(json_path, 'r') as f:\n",
    "            meta = json.load(f)\n",
    "\n",
    "        self.frames = meta['frames']\n",
    "        self.camera_angle_x = meta['camera_angle_x']\n",
    "        self.image_size = image_size  # (W, H)\n",
    "        self.device = device\n",
    "        self.base_dir = os.path.dirname(json_path)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(image_size[::-1])  # (H, W) for torchvision\n",
    "        ])\n",
    "\n",
    "        self.sfm_poses = sfm_poses\n",
    "        self.sfm_intrinsics = sfm_intrinsics\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "    def _rescale_intrinsics(self, intrinsics, orig_size, new_size):\n",
    "        scale_x = new_size[0] / orig_size[0]\n",
    "        scale_y = new_size[1] / orig_size[1]\n",
    "        intrinsics = intrinsics.clone()\n",
    "        intrinsics[0] *= scale_x  # fx\n",
    "        intrinsics[1] *= scale_y  # fy\n",
    "        intrinsics[2] *= scale_x  # cx\n",
    "        intrinsics[3] *= scale_y  # cy\n",
    "        return intrinsics\n",
    "\n",
    "    def _load_pose(self, frame, img_filename):\n",
    "        if self.sfm_poses and img_filename in self.sfm_poses:\n",
    "            return to_homogeneous(self.sfm_poses[img_filename]).to(self.device)\n",
    "        # Invert NeRF transform_matrix if no SfM\n",
    "        return torch.inverse(torch.tensor(frame['transform_matrix'], dtype=torch.float32).to(self.device))\n",
    "\n",
    "    def _load_intrinsics(self, img_filename, orig_size):\n",
    "        W, H = self.image_size\n",
    "        if self.sfm_intrinsics and img_filename in self.sfm_intrinsics:\n",
    "            fx, fy, cx, cy = self.sfm_intrinsics[img_filename].cpu()[:4]\n",
    "            intrinsics = torch.tensor([fx, fy, cx, cy], dtype=torch.float32)\n",
    "            intrinsics = self._rescale_intrinsics(intrinsics, orig_size, self.image_size)\n",
    "        else:\n",
    "            # Default NeRF-style intrinsics (assuming square pixels)\n",
    "            focal_x = 0.5 * W / np.tan(0.5 * self.camera_angle_x)\n",
    "            focal_y = 0.5 * H / np.tan(0.5 * self.camera_angle_x)\n",
    "            intrinsics = torch.tensor([focal_x, focal_y, W / 2, H / 2], dtype=torch.float32)\n",
    "\n",
    "        K = torch.tensor([\n",
    "            [intrinsics[0], 0, intrinsics[2]],\n",
    "            [0, intrinsics[1], intrinsics[3]],\n",
    "            [0, 0, 1]\n",
    "        ], dtype=torch.float32, device=self.device)\n",
    "\n",
    "        return K\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with torch.no_grad():  # No gradients needed for dataset loading\n",
    "            frame = self.frames[idx]\n",
    "            img_filename = os.path.basename(frame['file_path']) + '.png'\n",
    "            img_path = os.path.join(self.base_dir, frame['file_path'] + '.png')\n",
    "\n",
    "            # Load raw image to get original size\n",
    "            raw = iio.imread(img_path).astype(np.float32) / 255.0\n",
    "            if raw.shape[-1] == 4:  # Drop alpha if present\n",
    "                raw = raw[:, :, :3]\n",
    "            orig_height, orig_width = raw.shape[:2]\n",
    "\n",
    "            # Transform image (resize, normalize)\n",
    "            image = self.transform(raw).to(self.device)\n",
    "\n",
    "            # Load camera pose and intrinsics\n",
    "            pose = self._load_pose(frame, img_filename)\n",
    "            K = self._load_intrinsics(img_filename, (orig_width, orig_height))\n",
    "\n",
    "            return image, pose, K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d744023",
   "metadata": {},
   "source": [
    "# Gaussian Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3330dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_scale(points, k=3):\n",
    "    # Compute mean distance to k nearest neighbors\n",
    "    dists = torch.cdist(points, points)\n",
    "    dists[torch.arange(points.shape[0]), torch.arange(points.shape[0])] = float('inf')\n",
    "    topk, _ = torch.topk(dists, k=k, largest=False)\n",
    "    return topk.mean(dim=1, keepdim=True).expand(-1, 3)  # (N, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gaussians(sfm_points=None, device='cuda', N_default=10000):\n",
    "\n",
    "    # If we don't have Structure from Motion points, we just create a cloud.\n",
    "    if sfm_points:\n",
    "        xyz = sfm_points.to(device)\n",
    "    else:\n",
    "        xyz = torch.randn(N_default, 3, device=device) * 1.0  # unit sphere cloud\n",
    "        xyz = xyz / xyz.norm(dim=1, keepdim=True).clamp(min=1e-6)  # normalize to radius 1\n",
    "        xyz += 0.05 * torch.randn_like(xyz)  # jitter to avoid uniform sphere\n",
    "\n",
    "    N = xyz.shape[0]\n",
    "\n",
    "    # Unit quaternions (0, 0, 0, 1)\n",
    "    quat = torch.zeros(N, 4, device=device)\n",
    "    quat[:, 3] = 1.0\n",
    "\n",
    "    # Initialize alpha in [0,1], centered around 0.5\n",
    "    alpha = torch.clamp(0.5 + 0.1 * torch.randn(N, device=device), 0.0, 1.0)\n",
    "\n",
    "    # Spherical Harmonics coefficients\n",
    "    sh_order = 3 # R, G, B\n",
    "    n_sh_coeffs = (sh_order + 1) ** 2\n",
    "    sh_coeff = torch.clamp(0.5 + 0.1 * torch.randn(N, 3, n_sh_coeffs, device=device), 0.0, 1.0)\n",
    "\n",
    "    return {\n",
    "        'xyz': nn.Parameter(xyz),\n",
    "        'scale': nn.Parameter(torch.log(estimate_scale(xyz))),  # log scale for exponential later\n",
    "        'quat': nn.Parameter(quat),\n",
    "        'alpha': nn.Parameter(alpha),\n",
    "        'sh_coeff': nn.Parameter(sh_coeff),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3614b",
   "metadata": {},
   "source": [
    "# Differentiable Rasterizer for Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d22daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quat_to_rot_matrix(q):\n",
    "    \"\"\"\n",
    "    q: (N, 4) quaternion in (x, y, z, w) format\n",
    "    Returns: (N, 3, 3) rotation matrices\n",
    "    \"\"\"\n",
    "    q = F.normalize(q, dim=-1)  # ensure unit quaternion\n",
    "\n",
    "    x, y, z, w = q[:, 0], q[:, 1], q[:, 2], q[:, 3]\n",
    "\n",
    "    xx, yy, zz = x * x, y * y, z * z\n",
    "    xy, xz, yz = x * y, x * z, y * z\n",
    "    wx, wy, wz = w * x, w * y, w * z\n",
    "\n",
    "    R = torch.stack([\n",
    "        1 - 2*(yy + zz), 2*(xy - wz),     2*(xz + wy),\n",
    "        2*(xy + wz),     1 - 2*(xx + zz), 2*(yz - wx),\n",
    "        2*(xz - wy),     2*(yz + wx),     1 - 2*(xx + yy)\n",
    "    ], dim=-1).reshape(-1, 3, 3)\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quat_and_scale_to_covariance(q, s):\n",
    "    \"\"\"\n",
    "    q: (N, 4) quaternions (x, y, z, w)\n",
    "    s: (N, 3) scaling vectors (s_x, s_y, s_z)\n",
    "    Returns: (N, 3, 3) covariance matrices Σ\n",
    "    \"\"\"\n",
    "    R = quat_to_rot_matrix(q)        # (N, 3, 3)\n",
    "    S = torch.diag_embed(s)                     # (N, 3, 3)\n",
    "    SS_T = torch.matmul(S, S.transpose(1, 2))   # (N, 3, 3)\n",
    "    cov = torch.matmul(R, torch.matmul(SS_T, R.transpose(1, 2)))  # (N, 3, 3)\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5317e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_jacobian(cam_points, fx, fy):\n",
    "    \"\"\"\n",
    "    cam_points: (N, 3) camera-space coordinates\n",
    "    fx, fy: focal lengths\n",
    "    Returns: (N, 2, 3) Jacobian of perspective projection\n",
    "    \"\"\"\n",
    "    x, y, z = cam_points[:, 0], cam_points[:, 1], cam_points[:, 2]\n",
    "    eps = 1e-8  # avoid divide by zero\n",
    "\n",
    "    J = torch.zeros((cam_points.shape[0], 2, 3), device=cam_points.device)\n",
    "    \n",
    "    J[:, 0, 0] = fx / (z + eps)\n",
    "    J[:, 0, 1] = 0\n",
    "    J[:, 0, 2] = -fx * x / (z**2 + eps)\n",
    "\n",
    "    J[:, 1, 0] = 0\n",
    "    J[:, 1, 1] = fy / (z + eps)\n",
    "    J[:, 1, 2] = -fy * y / (z**2 + eps)\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec2445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_gaussians(points, cov, pose_w2c, K):\n",
    "\n",
    "    N = points.shape[0]\n",
    "    device = points.device\n",
    "\n",
    "    # Convert positions to homogeneous coordinates (N,4)\n",
    "    ones = torch.ones((N, 1), device=device)\n",
    "    positions_h = torch.cat([points, ones], dim=-1)\n",
    "\n",
    "    # Transform to camera coordinates (N,4)\n",
    "    positions_cam_h = (pose_w2c @ positions_h.T).T\n",
    "    positions_cam = positions_cam_h[:, :3]\n",
    "\n",
    "    # Extract rotation W (3x3)\n",
    "    W = pose_w2c[:3, :3]\n",
    "\n",
    "    # Rotate covariance matrices from world to camera coords:\n",
    "    # Σ_c = W Σ Wᵀ\n",
    "    W_expand = W.unsqueeze(0).expand(N, 3, 3)\n",
    "    cov_cam = W_expand @ cov @ W_expand.transpose(1, 2)\n",
    "\n",
    "    # Compute 2D projected points via perspective projection\n",
    "    x, y, z = positions_cam[:, 0], positions_cam[:, 1], positions_cam[:, 2]\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "\n",
    "    u = fx * (x / z) + cx\n",
    "    v = fy * (y / z) + cy\n",
    "    proj_points = torch.stack([u, v], dim=1)\n",
    "\n",
    "    # Compute Jacobian J of perspective projection (N, 2, 3)\n",
    "    eps = 1e-8\n",
    "    J = torch.zeros((N, 2, 3), device=device)\n",
    "    J[:, 0, 0] = fx / (z + eps)\n",
    "    J[:, 0, 2] = -fx * x / (z * z + eps)\n",
    "    J[:, 1, 1] = fy / (z + eps)\n",
    "    J[:, 1, 2] = -fy * y / (z * z + eps)\n",
    "\n",
    "    # Project covariance: Σ' = J Σ_c Jᵀ\n",
    "    cov2d = J @ cov_cam @ J.transpose(1, 2)\n",
    "\n",
    "    return cov2d, proj_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef89b7d1",
   "metadata": {},
   "source": [
    "# Adaptive Control of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13992d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_gaussians(gaussians, optimizer_xyz, optimizer_rest, eps_alpha):\n",
    "    with torch.no_grad():\n",
    "        alpha = torch.sigmoid(gaussians['opacity']).squeeze(1)\n",
    "        keep_mask = alpha >= eps_alpha\n",
    "\n",
    "        if not torch.any(~keep_mask):\n",
    "            return\n",
    "\n",
    "        for key, param in gaussians.items():\n",
    "            gaussians[key] = nn.Parameter(param[keep_mask])\n",
    "\n",
    "        optimizer_xyz.param_groups[0]['params'] = [gaussians['xyz']]\n",
    "        optimizer_rest.param_groups[0]['params'] = [p for k, p in gaussians.items() if k != 'xyz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6bf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_gaussian(mean, scale_log, quat, num_samples=2):\n",
    "    scale = torch.exp(scale_log)\n",
    "    cov = quat_and_scale_to_covariance(quat, scale)\n",
    "    dist = torch.distributions.MultivariateNormal(mean, covariance_matrix=cov)\n",
    "    return dist.sample((num_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f85397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_gaussians(base, mask, split_scale):\n",
    "    xyz = base['xyz'][mask]\n",
    "    scale_log = base['scale'][mask]\n",
    "    quat = base['quaternion'][mask]\n",
    "\n",
    "    scale = scale_log - torch.log(torch.tensor(split_scale, device=scale_log.device))\n",
    "    new_xyz = []\n",
    "\n",
    "    for i in range(xyz.shape[0]):\n",
    "        samples = sample_from_gaussian(\n",
    "            xyz[i],\n",
    "            torch.exp(scale_log[i]) / split_scale,\n",
    "            quat[i],\n",
    "            num_samples=2\n",
    "        )\n",
    "        new_xyz.append(samples)\n",
    "    new_xyz = torch.cat(new_xyz, dim=0)\n",
    "\n",
    "    return {\n",
    "        'xyz': new_xyz,\n",
    "        'color': base['color'][mask].repeat_interleave(2, dim=0),\n",
    "        'opacity': base['opacity'][mask].repeat_interleave(2, dim=0),\n",
    "        'scale': scale.repeat_interleave(2, dim=0),\n",
    "        'quaternion': quat.repeat_interleave(2, dim=0)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_gaussians(base, grad_unit, mask, offset_scale):\n",
    "    return {\n",
    "        'xyz': base['xyz'][mask] + grad_unit[mask] * offset_scale,\n",
    "        'color': base['color'][mask],\n",
    "        'opacity': base['opacity'][mask],\n",
    "        'scale': base['scale'][mask],\n",
    "        'quaternion': base['quaternion'][mask]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1680ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densify_gaussians(gaussians, optimizer_xyz, optimizer_rest, pose_w2c, settings):\n",
    "    tau_pos = settings['tau_pos']\n",
    "    densify_factor = settings['densify_factor']\n",
    "    scale_threshold = settings['scale_threshold']\n",
    "    clone_offset_scale = settings['clone_offset_scale']\n",
    "    split_scale = settings['split_scale']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if gaussians['xyz'].grad is None:\n",
    "            print(\"No positional grads, skipping densify\")\n",
    "            return\n",
    "\n",
    "        grad_view = (pose_w2c[:3, :3] @ gaussians['xyz'].grad.T).T\n",
    "        grad_norms = grad_view.norm(dim=1)\n",
    "\n",
    "        high_grad_mask = grad_norms > tau_pos\n",
    "        indices = torch.nonzero(high_grad_mask).squeeze(1)\n",
    "        if indices.numel() == 0:\n",
    "            print(\"No Gaussians to densify\")\n",
    "            return\n",
    "\n",
    "        num_to_densify = int(densify_factor * indices.numel())\n",
    "        densify_indices = indices[torch.randperm(indices.numel())[:num_to_densify]]\n",
    "\n",
    "        base = {k: gaussians[k][densify_indices] for k in ['xyz', 'color', 'opacity', 'scale', 'quaternion']}\n",
    "        grad_unit = grad_view[densify_indices] / grad_view[densify_indices].norm(dim=1, keepdim=True).clamp(min=1e-8)\n",
    "\n",
    "        scale = torch.exp(base['scale'])\n",
    "        is_small = scale.mean(dim=1) < scale_threshold\n",
    "\n",
    "        cloned = clone_gaussians(base, grad_unit, is_small, offset_scale=clone_offset_scale)\n",
    "        split = split_gaussians(base, is_small.logical_not(), split_scale=split_scale)\n",
    "\n",
    "        for key in gaussians:\n",
    "            new_data = torch.cat([cloned[key], split[key]], dim=0)\n",
    "            gaussians[key] = nn.Parameter(torch.cat([gaussians[key], new_data], dim=0))\n",
    "\n",
    "        print(f\"[Densify] Added {cloned['xyz'].shape[0] + split['xyz'].shape[0]} new Gaussians\")\n",
    "\n",
    "        optimizer_xyz.param_groups[0]['params'] = [gaussians['xyz']]\n",
    "        optimizer_rest.param_groups[0]['params'] = [p for k, p in gaussians.items() if k != 'xyz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_floaters(gaussians, alpha_reset_value=-5.0):\n",
    "    with torch.no_grad():\n",
    "        if 'opacity' in gaussians:\n",
    "            gaussians['opacity'].data.fill_(alpha_reset_value)\n",
    "            print(f\"[Reset Floaters] Set all opacity logits to {alpha_reset_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b06e0d",
   "metadata": {},
   "source": [
    "# Training Gaussian Splatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbad367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(tensor, filename):\n",
    "    # Clamp values to valid range [0, 1]\n",
    "    tensor = torch.clamp(tensor, 0.0, 1.0)\n",
    "\n",
    "    # Check for NaNs or infinite values and replace them safely\n",
    "    if torch.isnan(tensor).any() or torch.isinf(tensor).any():\n",
    "        print(f\"Warning: Image contains NaN or Inf values when saving {filename}\")\n",
    "        tensor = torch.nan_to_num(tensor, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "    # Convert tensor to HWC numpy uint8 image\n",
    "    img_np = (tensor.permute(1, 2, 0).cpu().detach().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    # Write image using imageio\n",
    "    iio.imwrite(filename, img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(settings):\n",
    "    assert settings is not None, \"Settings dictionary must be provided.\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # Load SfM data\n",
    "    poses_w2c_dict, intrinsics_dict, points = sfm_extract(settings['image_path'], device=device)\n",
    "\n",
    "    # Initialize Gaussians\n",
    "    gaussians = init_gaussians(points, device=device)\n",
    "\n",
    "    # Dataset + DataLoader with batch size\n",
    "    dataset = NeRFDataset(\n",
    "        json_path=settings['json_path'],\n",
    "        image_size=settings['image_size'],\n",
    "        device=device,\n",
    "        sfm_poses=poses_w2c_dict,\n",
    "        sfm_intrinsics=intrinsics_dict\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=settings['batch_size'], shuffle=True)\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_xyz = torch.optim.Adam([gaussians['xyz']], lr=settings['lr_xyz_init'])\n",
    "    optimizer_rest = torch.optim.Adam(\n",
    "        [p for k, p in gaussians.items() if k != 'xyz'],\n",
    "        lr=settings['lr_rest']\n",
    "    )\n",
    "\n",
    "    # Built-in PyTorch exponential LR scheduler for optimizer_xyz\n",
    "    scheduler_xyz = torch.optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer_xyz,\n",
    "        gamma=settings.get('lr_decay_factor', 0.99)  # decay factor per epoch\n",
    "    )\n",
    "\n",
    "    pbar = tqdm(range(settings['epochs']), desc=\"Training\")\n",
    "\n",
    "    for epoch in pbar:\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, poses_w2c, Ks in loader:\n",
    "            images = images.to(device)\n",
    "            poses_w2c = poses_w2c.to(device)\n",
    "            Ks = Ks.to(device)\n",
    "\n",
    "            optimizer_xyz.zero_grad()\n",
    "            optimizer_rest.zero_grad()\n",
    "\n",
    "            # Render batch\n",
    "            render = []\n",
    "            for i in range(images.shape[0]):\n",
    "                r = render_gaussians(gaussians, poses_w2c[i], Ks[i], settings['image_size'])\n",
    "                render.append(r)\n",
    "            render = torch.stack(render)\n",
    "\n",
    "            # Compute loss (L1 + D-SSIM)\n",
    "            l1_loss = F.l1_loss(render, images)\n",
    "            dssim_loss = 1 - ssim(render, images)\n",
    "            loss = (1 - settings['lambda']) * l1_loss + settings['lambda'] * dssim_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer_xyz.step()\n",
    "            optimizer_rest.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(loader)\n",
    "        current_lr = scheduler_xyz.get_last_lr()[0]\n",
    "        pbar.set_postfix(loss=f\"{avg_loss:.4f}\", lr_xyz=f\"{current_lr:.6f}\")\n",
    "\n",
    "        # Step the scheduler once per epoch\n",
    "        scheduler_xyz.step()\n",
    "\n",
    "        # Delete + Densify Gaussians\n",
    "        delete_gaussians(gaussians, optimizer_xyz, optimizer_rest, eps_alpha=settings['eps_alpha'])\n",
    "\n",
    "        if epoch % settings['densify_interval'] == 0:\n",
    "            densify_gaussians(gaussians, optimizer_xyz, optimizer_rest, poses_w2c[0], settings)\n",
    "\n",
    "        if epoch % settings['floaters_reset_interval'] == 0:\n",
    "            reset_floaters(gaussians, settings['floaters_reset_value'])\n",
    "\n",
    "        # Optional logging\n",
    "        if (epoch + 1) % settings.get('log_interval', 10) == 0 or epoch == 0:\n",
    "            save_img(render[0], f\"render_{epoch+1}.png\")\n",
    "            save_img(images[0], f\"image_{epoch+1}.png\")\n",
    "\n",
    "    # Save final render\n",
    "    save_img(render[0], \"final.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db99afd9",
   "metadata": {},
   "source": [
    "# Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'json_path': \"nerf_synthetic/lego/transforms_train.json\",\n",
    "    'image_path': \"nerf_synthetic/lego/train\",\n",
    "    'image_size': (256, 256),\n",
    "\n",
    "    'epochs': 1000,\n",
    "    'batch_size': 4,\n",
    "\n",
    "    'lr_xyz_init': 1e-3,\n",
    "    'lr_rest': 1e-2,\n",
    "    'lr_decay_factor': 0.95,\n",
    "\n",
    "    'lambda': 0.2,                   # weight for D-SSIM loss\n",
    "    'tau_pos': 0.0002,               # gradient threshold for densification\n",
    "    'densify_factor': 0.5,           # percentage of high-grad Gaussians to densify\n",
    "    'scale_threshold': 0.05,         # threshold for small vs large Gaussians\n",
    "    'clone_offset_scale': 0.01,      # offset applied when cloning small Gaussians\n",
    "    'split_scale': 1.6,              # factor to split large Gaussians\n",
    "    'eps_alpha': 0.01,               # alpha below which Gaussians are deleted\n",
    "    'floaters_reset_interval': 3000, # how often to reset alpha\n",
    "    'floaters_reset_value': -5.0,    # value to reset alpha to\n",
    "    'densify_interval': 100,         # how often to densify\n",
    "    'log_interval': 2                # how often to save images\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dda8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
